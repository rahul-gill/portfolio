---
title: Processes and threads
index: 1
---
## Introduction
- **process**: running/executing instance of a program
- there can be multiple processes of single program at the same time
> **jobs**: unit used as cpu usage

TODO: meaning of different process state
TODO: explaination of proc struct

- **process control block(PCB)**: data stucture containing info about process resources:  program counter, registers, state(running/queued/waiting/terminated etc.),global data section, scheduling info, mem management info, accounting info(process id, limits etc.), io info(list of open files etc.), threads info etc.
  for example:
- **thread**: execution units, have some process resources shared between them
- in linux
  - PCB data structure: `task_struct` in header file `sched.h`
  - these PCBs kept in a doubly linked list maintained by kernel
  - no differentiation between process and threads(parent-child hierarchy of processes)

```c
struct context{
	int eip, esp, ebp;
	int ebx, ecx, edx;
	int esi,edi;
};
enum proc_state{
	UNUSED, SLEEPING, RUNNABLE, RUNNING, EMBRYO, ZOMBIE
};
struct proc{
	char *mem;         // start of process memory
	uint sz;           // size of process memory
	char *kstack;      // bottom of kernel stack
	enum proc_state state;
	int pid;
	struct proc *parent;
	int killed;        // if zero, the process was killed
	struct file *oflie[NO_FILE];
	struct inode *cwd; //current working directory
	/* context is used in context switching(giving cpu to other process)
	 * trapframe holds state when an exception arise
	 */
	struct context context;
	struct trapframe *tf;
	/* chan: channel, sleeping on chan if points to NULL
	 *useful when for example process sleeps waiting for an input in console
	 */
	void *chan;
}
```

- process dispatched: process selected for execution; dispatcher does that
- long term scheduler(controls the degree of multiprogramming: number of processes in main memory) and short term scheduler(schedules cpu usage)
- medium term scheduler(swaps out to disk and load back in memory a process when there's a need; for example: when my ram can't handle android studio so somethings are swapped out to disk)
- cpu bound(mostly cpu) and io bound(mostly do io) process; processes can also be cpu and io heavy at the same time
- context of process and context switch
- ios have limited background process support but android have application component names `Service` which can be used for doing background tasks
## Creating processes
- process creation steps:
    - pid and a process-table entry is created and assigned to the process
    - code and static data is loaded in memory(lazily)
    - memory for stack is allocated and stack is intialized with argumetns of main function
    - heap memory is allocated
    - other tasks such as setting up 3 file descriptors: stdin, stdout, stderr etc. are done
    - process is scheduled to run(later or immedietly depending on cpu load)
- in linux there's a process which is parent of all process like init, openrc, systemd
  for example using `pstree` command on manjaro we get somthing like this
```
systemd─┬─NetworkManager───2*[{NetworkManager}]
        ├─kdeinit5─┬─2*[file.so]
        │          └─klauncher───2*[{klauncher}]
        ├─kwin_x11───9*[{kwin_x11}]
        ├─org_kde_powerde───6*[{org_kde_powerde}]
        ├─plasmashell─┬─dolphin───5*[{dolphin}]
        │             ├─konsole─┬─zsh───pstree
        │             │         └─7*[{konsole}]
        │             ├─ksysguardd
        │             └─10*[{plasmashell}]
        ├─sddm─┬─Xorg───2*[{Xorg}]
        │      ├─sddm-helper───startplasma-x11───{startplasma-x11}
        │      └─{sddm}
        ├─start_kdeinit
        ├─systemd─┬─(sd-pam)
        │         ├─dbus-daemon
        │         ├─dconf-service───2*[{dconf-service}]
        │         ├─kscreen_backend───2*[{kscreen_backend}]
        │         ├─pulseaudio───2*[{pulseaudio}]
        ├─systemd-journal
        ├─systemd-logind
        ├─systemd-machine
        ├─systemd-timesyn───{systemd-timesyn}
        └─systemd-udevd

```
- creating a child process in linux
```c
#include<stdio.h>
#include<stdlib.h>
#include<unistd.h>
int main(){
	pid_t pid;
	/* fork lazily clones the current process as a new child */
	pid = fork();
	if (pid < 0) {
		fprintf(stderr, "Fork Failed");
		exit(1); // exit can be used to terminate process
	}
	else if (pid == 0) { /* child process */
		/*the child will mutate into ls command?*/
		execlp("/bin/ls","ls",NULL);
	}
	else { /* parent process */
		/* wait for the child to complete */
		wait(NULL);
		printf("Child Complete");
	}
	return 0;
}
```
- in windows
```c
#include <stdio.h>
#include <windows.h>
int main(void){
	STARTUPINFO si;
	PROCESS_INFORMATION pi;
	// allocate memory
	ZeroMemory(&si, sizeof(si));
	si.cb = sizeof(si);
	ZeroMemory(&pi, sizeof(pi));

	// CreateProcess doesn't clone
	if (!CreateProcess(
		NULL, /*app name*/
		"C:\\WINDOWS\\system32\\mspaint.exe", /* command */
		NULL, /* don’t inherit process handle */
		NULL, /* don’t inherit thread handle */
		FALSE, /* disable handle inheritance */
		0, /* no creation flags */
		NULL, /* use parent’s environment block */
		NULL, /* use parent’s existing directory */
		&si,
		&pi
	)){
		fprintf(stderr, "Create Process Failed");
		return -1;
	}
	// pass handle of child and wait infinitely for its completion
	WaitForSingleObject(pi.hProcess, INFINITE);
	printf("Child Complete");
	CloseHandle(pi.hProcess);
	CloseHandle(pi.hThread);
}
```
- cascading termination: system don't allow children to exist if parent is terminated
- when a  process terminates, its resources are deallocated by system but its entry in the process table remain there until the parent calls `wait()`, because the process table contains the process’s exit status. If parent has not yet called `wait()`  and process terminates then its called as **zombie** process. For example when in the above code, if we do not call `wait()` and before the final return, add a line `scanf("%d",&x);` you'll see whats happening.
- if parent didn't called `wait()` and gets terminated, the children are left **orphans**. Linux address this scenario by assigning init process as the new parent to orphan processes. The init process periodically calles `wait()` to collect exit status of terminated processes and releasing their pid and process-table entry.
## Inter-process communication
- **cooperating processes** are those which can be affected by some other processes, for example when two processes share data.
- two models of IPC: shared memory and message passing. Shared memory is fast because message passing is done via system calls. Message passing is easier for sharing small amount of data.
- shared memory can cause cache coherency issue in a multi-core systems
- producer-consumer process
    - two processes shares a circular buffer `struct item buffer[BUFFER_SIZE]`; an integer `in` denotes the next free position and integer `out` denotes first full position in buffer.
    - buffer is empty when `in==out` and full when `(in+1) % BUFFER_SIZE == out`
```c
//producer
struct item next_produced;
while (true) {
	while (((in + 1) % BUFFER SIZE) == out)
		;
	buffer[in] = next produced;
	in = (in + 1) % BUFFER SIZE ;
}
```

```c
//consumer
struct item next_consumed;
while (true) {
	while (in == out)
		;
	next consumed = buffer[out];
	out = (out + 1) % BUFFER SIZE;
}
```
- one issue here is situation when both producer and consumer attempt to access the buffer concurrently; also the `while` thing is not good.
  <br/>
- message passing through ports such as in jupyter notebook. This can also be used to pass messages to processes on other devices such as adb shell passing messages to android phone.
- POSIX shared memory is organized using memory-mapped files, which associate the region of shared memory with a file. example:
```c
//common headers to be included
#include<stdio.h>
#include<sys/mman.h>
#include<sys/stat.h>        /* For mode constants */
#include<fcntl.h>           /* For O_* constants */
#include<unistd.h>
```

```c
//producer
//create a shared memory object;
//signature: int shm_open(const char *name, int oflag, mode_t mode);
int shm_fd = shm_open("axb", O_CREAT | O_RDWR, 0666);
//configure the size of object in bytes
ftruncate(shm_fd, 4096);
void *ptr = mmap(0, 4096, PROT_WRITE, MAP_SHARED, shm_fd, 0);

/* write to the shared memory object */
sprintf(ptr,"%s","hi ");
ptr += 3;
sprintf(ptr,"%s","hello");
ptr += 5;
```
```c
//consumer
int shm_fd = shm_open("axb", O_RDONLY, 0666);
void *ptr = mmap(0, 4096, PROT_READ, MAP_SHARED, shm_fd, 0);
printf("%s",(char *)ptr);
shm_unlink("axb");
```
- pipes: producer write to one end and consumer reads on teh other end; unix pipe call
    - in command line `ls -lah | grep myfile`
```c
//int pipe(int fd_arr[2]); //fd_arr[0]:read-end, fd_arr[1]:write-end
#include <stdlib.h>
#include <unistd.h>
int main(){
	int fildes[2];
	const int BSIZE = 100;
	char buf[BSIZE];
	ssize_t nbytes;
	int status;

	status = pipe(fildes);
	if (status == -1 ){
		fprintf(stderr, "error occured");
		exit(1);
	}

	switch (fork()) {
	case -1:
		fprintf(stderr, "error occured");
		exit(1);
		break;
	case 0:  /* Child - reads from pipe */
	   close(fildes[1]);                       /* Write end is unused */
	   nbytes = read(fildes[0], buf, BSIZE);   /* Get data from pipe */
	   /* At this point, a further read would see end-of-file ... */
	   close(fildes[0]);                       /* Finished with pipe */
	   exit(EXIT_SUCCESS);

	default:  /* Parent - writes to pipe */
	   close(fildes[0]);                       /* Read end is unused */
	   write(fildes[1], "Hello world\n", 12);  /* Write data on pipe */
	   close(fildes[1]);                       /* Child will see EOF */
	   exit(EXIT_SUCCESS);
	}
}
```

## Threads
- different execution units of same process
-  a process can have multiple threads
-  have its own program counter, registers state and stack but other resources such as memory and static data are shared
-  so now process can have multiple stacks but those stacks are usually small
- benefits of threads
    - responsiveness: time-consuming task done on other thread so it doesn't block the ui thread
    - resource sharing between threads
    - economical: doesn't require to allocate new resources for it because threads share resources
    - better performance: threads can run on different cores in parallel
- Amdahl's law: if $S$ is proportion of application which needs to be performed serially on a system with $N$ processing cores, then speedup done by adding more cores is $\leq \frac{N}{NS+(1-S)}$
- processor threads and hyper-threading(like intel says 8 cores 16 threads):
  For each processor core, the OS addresses two virtual(logical) cores and shares the workload between them. Both have their own processor state and both can be individually halted, interrupted or directed to execute a specified thread.One physical core appears as two processors to the OS, allowing concurrent scheduling of two processes per core.Certain sections of the processor are duplicate that store the architectural state but main execution resources, caches etc. are shared.

- challenges in programming for multicore systems
    - identifying tasks that can be executed in parallel
    - handling splitting and sync of data accessed and manipulated by tasks
    - testing and debugging
- there are two kinds of threads: user threads and kernel threads. User threads are maintained by some thread library and kernel threads are maintained by kernel. user threads need to be mapped to kernel threads to be executed
- thread models
    - one to one model: 1:1 relationship between kernel and user threads
    - many to many model
    - many to one model: many user threads mapped to single kernel thread
    - two level model: hybrid of 1:1 and m:n model
- [green threads](https://c9x.me/articles/gthreads/intro.html): user mode threads, many to one model, useful when doing io tasks. The article is amazing.
- pthread library for threads(NPTL implementation in linux 1:1 type so a new thread -> a new process)
```c
int pnum = 0; /* shared by the threads */
static const int tot = 100;
void *runner(void *param);

int main(int argc, char *argv[]){
    pthread_t tid[tot];
    pthread_attr_t attr;

    pthread_attr_init(&attr);
    //pthread_create's last argument(arguments for runner) are void* but cheated I
    for(int i=0; i<tot; i++)
        pthread_create(&tid[i],&attr,runner,i);
    for(int i=0; i<tot; i++)
        pthread_join(tid[i],NULL);
    printf("done\n");
}

void *runner(void *param){
    printf("thread no. %d\n", param);
    pthread_exit(0);
}
```
- `clone` sycall is used for thread type of things in linux
    - it provides precise control over what pieces of execution context are shared between the calling process and the child process.
    - It uses flags such as `CLONE_FS`(file system shared),  `CLONE_VS`(memory space shared),  `CLONE_SIGHAND`(signal handlers shared),  `CLONE_FILES`(open files shared)
### Implicit threading
- passing thread creation and management responsibilities to compilers and run time library
- thread pools: create a number of threads at process startup and place them into a pool.If some work needs to be done, a thread from this pool is awakened and passed the work, if one is available. If no thread is available, the sysem waits until one becomes free
- benefits of thread pools
    - limits the number of threads existing at a time instance. For example if server creates a new thread for each request, then som many concurrent requests can create so many threads exhausting sytem resources
    - faster because the thread to be used is already created
    - seperating different kinds of tasks(for example in android there are thread pools: main for cpu heavy work, io and ui.). Different thread pools handle the executions differently
- number of threads in pools can be heuristically determined or can be adjusted dynamically according to usage patterns.
- openmp example: summing elements of two arrays
```c
#include<omp.h>
#pragma omp parallel for
for (i = 0; i < N; i++) {
	c[i] = a[i] + b[i];
}
```
- grand central dispatch(apple thing)
    - two types of dispatch queues: serial and concurrent
    - three types of priorities: low, default and high
    - example
  ```c
  dispatch_queue_t queue = dispatch_get_global_queue(
      DISPATCH_QUEUE PRIORITY_DEFAULT, 0);
  dispatch async(queue, ˆ{ printf("I am a block."); });
  ```
- kotlin coroutines and goroutines??
- challenges with threads
    - should fork clone the forking thread only or all threads
    - how threads handle signals
    - how threads are cancelled: deffered cancellation(target thread periodically checks if it should terminate) or asynchronous cancellation(immediate termination; can be disaster)
    - so pthread uses `pthread_cancel` which requests the thread to be cancelled and to check if it cancelled, it must be joined with. The thread checks for this requests at certain points in programs(called cancellation points) and thread can install a function(cleanup handlers) to be executed before it cancels. A number of functions are cancellation points like `pthread_testcancel`, `pthread_cond_wait` etc.
    - thread local storage(different from local variables)
    - communication between thread library and kernel
- **LWP(lighweight process)**: Many systems implementing either the many-to-many or the two-level model place an this intermediate data structure between the user and kernel threads.
    - To the user-thread library, the LWP appears to be a virtual processor on which the application can schedule a user thread to run.
    - Each LWP is attached to a kernel thread which os  schedules to run on physical processors
    - if kernel thread blocks then LWP blocks and then user thread blocks
    - app may require any number of LWPs to run efficiently
- **Scheduler activation** a scheme for communication between user-thread library and kernel
    - kernel provides app with a set of virtual processors(LWPs) on which the app can schedule user threads
    - kernel informs the app about certain events with a proceducer named **upcall**
    - thread library have upcall handlers which handle the upcall and run on some virtual processor
- scenario: some thread is about to block
    - kernel makes an upcall to the app informing it that a thread is about to block and identifies the specific thread.
    - kernel allocates new virtual processor for the application
    - app run the upcall handler on this new virtual processor
    - upcall handler saves the state of the blocking thread and then schedules another thread to run
- scenario: the event that the blocking thread was waiting for occurs
    - first 3 steps same as above
    - upcall handler schedules the unblocked thread
